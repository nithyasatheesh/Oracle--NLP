{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srgXwrhSFveF"
   },
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fP2mpB55FjlH"
   },
   "outputs": [],
   "source": [
    "## Speech Of DR APJ Abdul Kalam\n",
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over\n",
    "               the world have come and invaded us, captured our lands, conquered our minds.\n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours.\n",
    "               Yet we have not done this to any other nation. We have not conquered anyone.\n",
    "               We have not grabbed their land, their culture,\n",
    "               their history and tried to enforce our way of life on them.\n",
    "               Why? Because we respect the freedom of others.That is why my\n",
    "               first vision is that of freedom. I believe that India got its first vision of\n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India\n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be\n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of\n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.\n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjhO4WdyFu1i"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PejVcxCUVEEN"
   },
   "outputs": [],
   "source": [
    "#apply stopwords and filter and then apply stemming\n",
    "for i in range(len(sentences)):\n",
    "  words=nltk.word_tokenize(sentences[i])  # all stopwords are in lowercase\n",
    "  words=[stemmer.stem(x) for x in words if x not in set(stopwords.words('english'))]\n",
    "  #convert all the list of words into sentences\n",
    "  sentences[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4-loepfV7iS",
    "outputId": "d17c420d-84d6-4b57-9452-8f4ec8138115"
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7VFo0K6V8bQ"
   },
   "outputs": [],
   "source": [
    "lemmatizer="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpO3WV-1YezG",
    "outputId": "9ee25f2a-61dd-49e6-e14c-cf1966e8d94e"
   },
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtU9Q-GtYHHM"
   },
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(paragraph)\n",
    "for i in range(len(sentences)):\n",
    "  words=nltk.word_tokenize(sentences[i].lower())\n",
    "  words=[lemmatizer.lemmatize(word,pos='v') for word in words if word not in set(stopwords.words('english'))]\n",
    "  sentences[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oqd7IDhfYbJM",
    "outputId": "41820749-5590-425b-bce0-5b7117f6502f"
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bh0FM_dYiHa"
   },
   "outputs": [],
   "source": [
    "#SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXiZvrY5bL8o"
   },
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(paragraph)\n",
    "for i in range(len(sentences)):\n",
    "  words=nltk.word_tokenize(sentences[i].lower())\n",
    "  words=[snowballstemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "  sentences[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2nwdAaibW18",
    "outputId": "340503d6-7daf-43e4-b2c0-929074b67d74"
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "XAzpxPpabYDW",
    "outputId": "b274df78-dd61-4d01-b68a-850dedf72fc3"
   },
   "outputs": [],
   "source": [
    "#fairly, sportingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pZ_hDkJc_cO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
