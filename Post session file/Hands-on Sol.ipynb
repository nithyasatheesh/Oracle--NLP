{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c18e072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last\n",
      "week\n",
      ",\n",
      "the\n",
      "University\n",
      "of\n",
      "Cambridge\n",
      "shared\n",
      "its\n",
      "own\n",
      "research\n",
      "that\n",
      "shows\n",
      "if\n",
      "everyone\n",
      "wears\n",
      "a\n",
      "mask\n",
      "outside\n",
      "home\n",
      ",\n",
      "dreaded\n",
      "‘\n",
      "second\n",
      "wave\n",
      "’\n",
      "of\n",
      "the\n",
      "pandemic\n",
      "can\n",
      "be\n",
      "avoided\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "text=\"Last week, the University of Cambridge shared its own research that shows if everyone wears a mask outside home,dreaded ‘second wave’ of the pandemic can be avoided.\"\n",
    "tokens=nltk.word_tokenize(text)\n",
    "for token in tokens:\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b7a913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outbreak coronavirus disease 2019 (COVID-19) created global health crisis deep impact way perceive world everyday lives. rate contagion patterns transmission threatens sense agency, safety measures put place contain spread virus also require social distancing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nithyalakshmim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "text = \"\"\"the outbreak of coronavirus disease 2019 (COVID-19) has created a global health crisis that has had a deep impact on the way we perceive our world and our everyday lives. Not only the rate of contagion and patterns of transmission threatens our sense of agency, but the safety measures put in place to contain the spread of the virus also require social distancing\"\"\"\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d11938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the outbreak of coronavirus disease 2019 COVID19 has created a global health crisis that has had a deep impact on the way we perceive our world and our everyday lives Not only the rate of contagion and patterns of transmission threatens our sense of agency but the safety measures put in place to contain the spread of the virus also require social distancing by refraining from doing what is inherently human which is to find solace in the company of others Within this context of physical threat social and physical distancing as well as public alarm what has been and can be the role of the different mass media channels in our lives on individual social and societal levels Mass media have long been recognized as powerful forces shaping how we experience the world and ourselves This recognition is accompanied by a growing volume of research that closely follows the footsteps of technological transformations eg radio movies television the internet mobiles and the zeitgeist eg cold war 911 climate change in an attempt to map mass media major impacts on how we perceive ourselves both as individuals and citizens Are media broadcast and digital still able to convey a sense of unity reaching large audiences or are messages lost in the noisy crowd of mass selfcommunication \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "text=\"\"\"the outbreak of coronavirus disease 2019 (COVID-19) has created a global health crisis that has had a deep impact on the way we perceive our world and our everyday lives. Not only the rate of contagion and patterns of transmission threatens our sense of agency, but the safety measures put in place to contain the spread of the virus also require social distancing by refraining from doing what is inherently human, which is to find solace in the company of others. Within this context of physical threat, social and physical distancing, as well as public alarm, what has been (and can be) the role of the different mass media channels in our lives on individual, social and societal levels? Mass media have long been recognized as powerful forces shaping how we experience the world and ourselves. This recognition is accompanied by a growing volume of research, that closely follows the footsteps of technological transformations (e.g. radio, movies, television, the internet, mobiles) and the zeitgeist (e.g. cold war, 9/11, climate change) in an attempt to map mass media major impacts on how we perceive ourselves, both as individuals and citizens. Are media (broadcast and digital) still able to convey a sense of unity reaching large audiences, or are messages lost in the noisy crowd of mass self-communication? \"\"\"\n",
    "# Remove punctuation using not in\n",
    "cleaned_text = ''.join([char for char in text if char not in string.punctuation])\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff49cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nithyalakshmim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nithyalakshmim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Text: Dancing be an art . Students should be teach dance as a subject in school . I dance in many of my school function . Some people be always hesitate to dance .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "text = \"\"\"Dancing is an art. Students should be taught dance as a subject in schools. \n",
    "I danced in many of my school function. Some people are always hesitating to dance.\"\"\"\n",
    "\n",
    "# Tokenize and lemmatize (without POS tags)\n",
    "lemmatized_text = ' '.join([lemmatizer.lemmatize(word,pos='v') for word in word_tokenize(text)])\n",
    "\n",
    "print(\"Lemmatized Text:\", lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b95acadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nithyalakshmim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nithyalakshmim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['James', 'Microsoft', 'manchester', 'likes', 'flute']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Define input text\n",
    "text = \"James works at Microsoft. She lives in manchester and likes to play the flute\"\n",
    "\n",
    "# Tokenize the text\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Perform Part of Speech tagging\n",
    "tagged_words = pos_tag(words)\n",
    "\n",
    "# Extract nouns (NN, NNS, NNP, NNPS represent different noun types)\n",
    "nouns = [word for word, pos in tagged_words if pos in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
    "\n",
    "# Output the nouns\n",
    "nouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae9591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e175059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f231c92",
   "metadata": {},
   "source": [
    "- Load the data\n",
    "- Preprocess text (remove stopwords, lowercase, and tokenize)\n",
    "- Convert text to numerical features using TF-IDF\n",
    "- Train a machine learning classifier (Logistic Regression)\n",
    "- Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4be2b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complaint ID</th>\n",
       "      <th>Complaint Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMP00001</td>\n",
       "      <td>I was charged twice for the same transaction.</td>\n",
       "      <td>Loan Issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMP00002</td>\n",
       "      <td>Suspicious transactions appeared on my credit ...</td>\n",
       "      <td>Loan Issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMP00003</td>\n",
       "      <td>My credit card application was rejected withou...</td>\n",
       "      <td>Account Issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMP00004</td>\n",
       "      <td>My debit card was blocked without notification.</td>\n",
       "      <td>Loan Issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMP00005</td>\n",
       "      <td>The interest rate applied to my loan is incorr...</td>\n",
       "      <td>Technical Issue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Complaint ID                                     Complaint Text  \\\n",
       "0     CMP00001      I was charged twice for the same transaction.   \n",
       "1     CMP00002  Suspicious transactions appeared on my credit ...   \n",
       "2     CMP00003  My credit card application was rejected withou...   \n",
       "3     CMP00004    My debit card was blocked without notification.   \n",
       "4     CMP00005  The interest rate applied to my loan is incorr...   \n",
       "\n",
       "          Category  \n",
       "0       Loan Issue  \n",
       "1       Loan Issue  \n",
       "2    Account Issue  \n",
       "3       Loan Issue  \n",
       "4  Technical Issue  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"D://Files//bank_complaints_2500.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78cd2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.196\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Account Issue       0.19      0.29      0.23       104\n",
      "  Billing Error       0.19      0.18      0.18       101\n",
      "          Fraud       0.22      0.23      0.23        96\n",
      "     Loan Issue       0.19      0.30      0.23        92\n",
      "Technical Issue       0.00      0.00      0.00       107\n",
      "\n",
      "       accuracy                           0.20       500\n",
      "      macro avg       0.16      0.20      0.17       500\n",
      "   weighted avg       0.16      0.20      0.17       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nithyalakshmim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\nithyalakshmim\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nithyalakshmim\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nithyalakshmim\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Download stopwords if not already done\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"D://Files//bank_complaints_2500.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check for missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['Cleaned_Text'] = df['Complaint Text'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['Cleaned_Text']).toarray()\n",
    "y = df['Category']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b28ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nithyalakshmim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nithyalakshmim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nithyalakshmim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.196\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Account Issue       0.19      0.29      0.23       104\n",
      "  Billing Error       0.19      0.18      0.18       101\n",
      "          Fraud       0.22      0.23      0.23        96\n",
      "     Loan Issue       0.19      0.30      0.23        92\n",
      "Technical Issue       0.00      0.00      0.00       107\n",
      "\n",
      "       accuracy                           0.20       500\n",
      "      macro avg       0.16      0.20      0.17       500\n",
      "   weighted avg       0.16      0.20      0.17       500\n",
      "\n",
      "     Complaint ID                                     Complaint Text  \\\n",
      "0        CMP00001      I was charged twice for the same transaction.   \n",
      "1        CMP00002  Suspicious transactions appeared on my credit ...   \n",
      "2        CMP00003  My credit card application was rejected withou...   \n",
      "3        CMP00004    My debit card was blocked without notification.   \n",
      "4        CMP00005  The interest rate applied to my loan is incorr...   \n",
      "...           ...                                                ...   \n",
      "2495     CMP02496      I was charged twice for the same transaction.   \n",
      "2496     CMP02497  The interest rate applied to my loan is incorr...   \n",
      "2497     CMP02498      I was charged twice for the same transaction.   \n",
      "2498     CMP02499  Suspicious transactions appeared on my credit ...   \n",
      "2499     CMP02500  I need to change my mailing address, but your ...   \n",
      "\n",
      "             Category                                       Cleaned_Text  \\\n",
      "0          Loan Issue                          charged twice transaction   \n",
      "1          Loan Issue  suspicious transaction appeared credit card st...   \n",
      "2       Account Issue    credit card application rejected without reason   \n",
      "3          Loan Issue            debit card blocked without notification   \n",
      "4     Technical Issue               interest rate applied loan incorrect   \n",
      "...               ...                                                ...   \n",
      "2495    Billing Error                          charged twice transaction   \n",
      "2496            Fraud               interest rate applied loan incorrect   \n",
      "2497    Account Issue                          charged twice transaction   \n",
      "2498  Technical Issue  suspicious transaction appeared credit card st...   \n",
      "2499  Technical Issue  need change mailing address online form isnt w...   \n",
      "\n",
      "     Predicted Category  \n",
      "0         Billing Error  \n",
      "1            Loan Issue  \n",
      "2                 Fraud  \n",
      "3         Account Issue  \n",
      "4         Account Issue  \n",
      "...                 ...  \n",
      "2495      Billing Error  \n",
      "2496      Account Issue  \n",
      "2497      Billing Error  \n",
      "2498         Loan Issue  \n",
      "2499      Account Issue  \n",
      "\n",
      "[2500 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithyalakshmim\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nithyalakshmim\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nithyalakshmim\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"D://Files//bank_complaints_2500.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop rows with missing data\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Text preprocessing function with lemmatization\n",
    "def preprocess_text(text):\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    stop=stopwords.words('english')\n",
    "    # Tokenize and lemmatize, removing stopwords\n",
    "    text = \" \".join(\n",
    "        [lemmatizer.lemmatize(word) for word in text.split() if word not in stop]\n",
    "    )\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['Cleaned_Text'] = df['Complaint Text'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X = vectorizer.fit_transform(df['Cleaned_Text']).toarray()\n",
    "y = df['Category']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Make predictions for all data\n",
    "df['Predicted Category'] = model.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "# Save merged results to a CSV\n",
    "output_file = \"D://Files//bank_complaints_with_predictions_lemmatized.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "#print(f\"Predictions successfully merged and saved to: {output_file}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9a0dd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.095*\"new\" + 0.071*\"learn\" + 0.048*\"If\" + 0.048*\"language\" + 0.048*\"things\"'), (1, '0.062*\"life\" + 0.046*\"may\" + 0.031*\"much\" + 0.031*\"home\" + 0.031*\"lot\"'), (2, '0.042*\"may\" + 0.036*\"experience\" + 0.028*\"realise\" + 0.028*\"home\" + 0.028*\"never\"'), (3, '0.064*\"travel\" + 0.046*\"learn\" + 0.028*\"If\" + 0.028*\"country\" + 0.027*\"find\"'), (4, '0.090*\"travel\" + 0.044*\"\\'\" + 0.041*\"time\" + 0.041*\"-\" + 0.028*\":\"')]\n"
     ]
    }
   ],
   "source": [
    "# Import gensim, nltk\n",
    "import gensim\n",
    "from gensim import models, corpora\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "texts= [\"\"\"It's all about travel. I travel a lot.  those who do not travel read only a page.” – said Saint Augustine. He was a great travel person. Travelling can teach you more than any university course. You learn about the culture of the country you visit. If you talk to locals, you will likely learn about their thinking, habits, traditions and history as well.If you travel, you will not only learn about foreign cultures, but about your own as well. You will notice the cultural differences, and will find out what makes your culture unique. After retrurning from a long journey, you will see your country with new eyes.\"\"\",\n",
    "        \"\"\" You can learn a lot about yourself through travelling. You can observe how you feel beeing far from your country. You will find out how you feel about your homeland.You should travel You will realise how you really feel about foreign people. You will find out how much you know/do not know about the world. You will be able to observe how you react in completely new situations. You will test your language, orientational and social skills. You will not be the same person after returning home.During travelling you will meet people that are very different from you. If you travel enough, you will learn to accept and appreciate these differences. Traveling makes you more open and accepting.\"\"\",\n",
    "        \"\"\"Some of my most cherished memories are from the times when I was travelling. If you travel, you can experience things that you could never experience at home. You may see beautiful places and landscapes that do not exist where you live. You may meet people that will change your life, and your thingking. You may try activities that you have never tried before.Travelling will inevitably make you more independent and confident. You will realise that you can cope with a lot of unexpected situations. You will realise that you can survive without all that help that is always available for you at home. You will likely find out that you are much stronger and braver than you have expected.\"\"\",\n",
    "        \"\"\"If you travel, you may learn a lot of useful things. These things can be anything from a new recepie, to a new, more effective solution to an ordinary problem or a new way of creating something.Even if you go to a country where they speak the same language as you, you may still learn some new words and expressions that are only used there. If you go to a country where they speak a different language, you will learn even more.\"\"\",\n",
    "        \"\"\"After arriving home from a long journey, a lot of travellers experience that they are much more motivated than they were before they left. During your trip you may learn things that you will want to try at home as well. You may want to test your new skills and knowledge. Your experiences will give you a lot of energy.During travelling you may experience the craziest, most exciting things, that will eventually become great stories that you can tell others. When you grow old and look back at your life and all your travel experiences, you will realise how much you have done in your life and your life was not in vain. It can provide you with happiness and satisfaction for the rest of your life.\"\"\",\n",
    "        \"\"\"The benefits of travel are not just a one-time thing: travel changes you physically and psychologically. Having little time or money isn't a valid excuse. You can travel for cheap very easily. If you have a full-time job and a family, you can still travel on the weekends or holidays, even with a baby. travel  more is likely to have a tremendous impact on your mental well-being, especially if you're no used to going out of your comfort zone. Trust me: travel more and your doctor will be happy. Be sure to get in touch with your physician, they might recommend some medication to accompany you in your travels, especially if you're heading to regions of the globe with potentially dangerous diseases.\"\"\",\n",
    "        \"\"\"Sure, you probably feel comfortable where you are, but that is just a fraction of the world! If you are a student, take advantage of programs such as Erasmus to get to know more people, experience and understand their culture. Dare traveling to regions you have a skeptical opinion about. I bet that you will change your mind and realize that everything is not so bad abroad.\"\"\",\n",
    "        \"\"\" So, travel makes you cherish life. Let's travel more . Share your travel diaries with us too\"\"\"\n",
    "        ]\n",
    "\n",
    "# Before topic extraction, we remove punctuations and stopwords.\n",
    "my_stopwords=set(stopwords.words('english'))\n",
    "punctuations=['.','!',',',\"You\",\"I\"]\n",
    "\n",
    "# We prepare a list containing lists of tokens of each text\n",
    "all_tokens=[]\n",
    "for text in texts:\n",
    "  tokens=[]\n",
    "  raw=nltk.wordpunct_tokenize(text)\n",
    "  for token in raw:\n",
    "    if token not in my_stopwords:\n",
    "      if token not in punctuations:\n",
    "        tokens.append(token)\n",
    "        all_tokens.append(tokens)\n",
    "\n",
    "# Creating a gensim dictionary and the matrix\n",
    "dictionary = corpora.Dictionary(all_tokens)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in all_tokens]\n",
    "\n",
    "# Building the model and training it with the matrix \n",
    "from gensim.models.ldamodel import LdaModel\n",
    "model = LdaModel(doc_term_matrix, num_topics=5, id2word = dictionary,passes=40)\n",
    "\n",
    "print(model.print_topics(num_topics=5,num_words=5))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6382daef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('new', 0.8211485650309772), ('learn', 0.6463001788333005), ('speak', 0.6158675676941282), ('language', 0.5637278950224253), ('country', 0.4755700130918015), ('things', 0.4452755791123397)]\n",
      "Topic 1:\n",
      "[('life', 0.4805173691445791), ('home', 0.44307227031667207), ('experience', 0.4268565297716629), ('realise', 0.3477242927765786), ('travelling', 0.30779839520996877), ('things', 0.29289780652255937)]\n",
      "Topic 2:\n",
      "[('feel', 0.4784804898833762), ('know', 0.3926111711693413), ('people', 0.3360738905037918), ('world', 0.3066615243894442), ('traveling', 0.3066615243894442), ('bet', 0.2585566276489277)]\n",
      "Topic 3:\n",
      "[('time', 0.4618656937234789), ('especially', 0.30791046248231935), ('zone', 0.15395523124115967), ('dangerous', 0.15395523124115967), ('excuse', 0.15395523124115967), ('benefits', 0.15395523124115967)]\n",
      "Topic 4:\n",
      "[('cherish', 0.4998741089783608), ('diaries', 0.4998741089783608), ('share', 0.4998741089783608), ('let', 0.4998741089783608), ('life', 0.37578968306913446), ('makes', 0.3624156674209144)]\n",
      "Topic 5:\n",
      "[('learn', 0.31900726383377787), ('culture', 0.26130152658463307), ('country', 0.23849340283892237), ('locals', 0.16098303072051007), ('eyes', 0.16098303072051007), ('retrurning', 0.16098303072051007)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts= [\"\"\"It's all about travel. I travel a lot.  those who do not travel read only a page.” – said Saint Augustine. He was a great travel person. Travelling can teach you more than any university course. You learn about the culture of the country you visit. If you talk to locals, you will likely learn about their thinking, habits, traditions and history as well.If you travel, you will not only learn about foreign cultures, but about your own as well. You will notice the cultural differences, and will find out what makes your culture unique. After retrurning from a long journey, you will see your country with new eyes.\"\"\",\n",
    "        \"\"\" You can learn a lot about yourself through travelling. You can observe how you feel beeing far from your country. You will find out how you feel about your homeland.You should travel You will realise how you really feel about foreign people. You will find out how much you know/do not know about the world. You will be able to observe how you react in completely new situations. You will test your language, orientational and social skills. You will not be the same person after returning home.During travelling you will meet people that are very different from you. If you travel enough, you will learn to accept and appreciate these differences. Traveling makes you more open and accepting.\"\"\",\n",
    "        \"\"\"Some of my most cherished memories are from the times when I was travelling. If you travel, you can experience things that you could never experience at home. You may see beautiful places and landscapes that do not exist where you live. You may meet people that will change your life, and your thingking. You may try activities that you have never tried before.Travelling will inevitably make you more independent and confident. You will realise that you can cope with a lot of unexpected situations. You will realise that you can survive without all that help that is always available for you at home. You will likely find out that you are much stronger and braver than you have expected.\"\"\",\n",
    "        \"\"\"If you travel, you may learn a lot of useful things. These things can be anything from a new recepie, to a new, more effective solution to an ordinary problem or a new way of creating something.Even if you go to a country where they speak the same language as you, you may still learn some new words and expressions that are only used there. If you go to a country where they speak a different language, you will learn even more.\"\"\",\n",
    "        \"\"\"After arriving home from a long journey, a lot of travellers experience that they are much more motivated than they were before they left. During your trip you may learn things that you will want to try at home as well. You may want to test your new skills and knowledge. Your experiences will give you a lot of energy.During travelling you may experience the craziest, most exciting things, that will eventually become great stories that you can tell others. When you grow old and look back at your life and all your travel experiences, you will realise how much you have done in your life and your life was not in vain. It can provide you with happiness and satisfaction for the rest of your life.\"\"\",\n",
    "        \"\"\"The benefits of travel are not just a one-time thing: travel changes you physically and psychologically. Having little time or money isn't a valid excuse. You can travel for cheap very easily. If you have a full-time job and a family, you can still travel on the weekends or holidays, even with a baby. travel  more is likely to have a tremendous impact on your mental well-being, especially if you're no used to going out of your comfort zone. Trust me: travel more and your doctor will be happy. Be sure to get in touch with your physician, they might recommend some medication to accompany you in your travels, especially if you're heading to regions of the globe with potentially dangerous diseases.\"\"\",\n",
    "        \"\"\"Sure, you probably feel comfortable where you are, but that is just a fraction of the world! If you are a student, take advantage of programs such as Erasmus to get to know more people, experience and understand their culture. Dare traveling to regions you have a skeptical opinion about. I bet that you will change your mind and realize that everything is not so bad abroad.\"\"\",\n",
    "        \"\"\" So, travel makes you cherish life. Let's travel more . Share your travel diaries with us too\"\"\"\n",
    "        ]\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Defining the vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000,  max_df = 0.5, smooth_idf=True)\n",
    "\n",
    "# Transforming the tokens into the matrix form through .fit_transform()\n",
    "nmf_matrix= vectorizer.fit_transform(texts)\n",
    "from sklearn.decomposition import NMF\n",
    "nmf_model = NMF(n_components=6)\n",
    "nmf_model.fit(nmf_matrix)\n",
    "\n",
    "# Function to print topics\n",
    "def print_topics_nmf(model, vectorizer, top_n=6):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        \n",
    "print_topics_nmf(nmf_model,vectorizer)\n",
    "#> Topic 0:\n",
    "#> [('new', 0.6329770846997606), ('learn', 0.498103898259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc64814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
